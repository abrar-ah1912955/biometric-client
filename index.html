<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection</title>
    <script src="https://cdn.jsdelivr.net/gh/cgarciagl/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        .camera {
            background-color: #ececec;
            margin: 5rem auto;
            border-radius: 10px;
            box-shadow: rgba(50, 50, 93, 0.25) 0px 50px 100px -20px, rgba(0, 0, 0, 0.3) 0px 30px 60px -30px;
            padding: 2rem;
        }

        .photo {
            display: block;
            box-shadow: rgba(149, 157, 165, 0.2) 0px 8px 24px;
            height: 200px;
        }

        .output {
            display: flex;
            padding: 1rem 2rem;
            justify-content: center;
        }
    </style>
</head>

<body>
    <div class="contentarea">
        <div class="camera">
            <video id="video">Video stream not available.</video>
            <button id="startbutton">Take photo</button>
            <button id="stopButton">Stop video</button>
            <button id="startButton">Start video</button>
            <button id="check">Check</button>

        </div>
        <canvas id="canvas" style="display: none;"> </canvas>
        <div class="output">
            <div>
                <p>Current Image:</p>
                <img id="photo" class="photo" alt="The second screen capture will appear in this box." />
            </div>
            <div>
                <p>Reference Image:</p>
                <img id="refPhoto" class="photo" alt="The screen capture will appear in this box." />
            </div>
        </div>
        <p>
            Visit MDN's article
            <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Taking_still_photos">
                Taking still photos with WebRTC</a>
            to learn more about the technologies used here.
        </p>
    </div>


    <script>
        (() => {
            // The width and height of the captured photo. We will set the
            // width to the value defined here, but the height will be
            // calculated based on the aspect ratio of the input stream.

            const width = 320; // We will scale the photo width to this
            let height = 0; // This will be computed based on the input stream

            // |streaming| indicates whether or not we're currently streaming
            // video from the camera. Obviously, we start at false.

            let streaming = false;

            // The various HTML elements we need to configure or control. These
            // will be set by the startup() function.

            let video = null;
            let canvas = null;
            let photo = null;
            let refPhoto = null;
            let startbutton = null;

            function showViewLiveResultButton() {
                if (window.self !== window.top) {
                    // Ensure that if our document is in a frame, we get the user
                    // to first open it in its own tab or window. Otherwise, it
                    // won't be able to request permission for camera access.
                    document.querySelector(".contentarea").remove();
                    const button = document.createElement("button");
                    button.textContent = "View live result of the example code above";
                    document.body.append(button);
                    button.addEventListener("click", () => window.open(location.href));
                    return true;
                }
                return false;
            }

            function startup() {
                if (showViewLiveResultButton()) {
                    return;
                }
                video = document.getElementById("video");
                canvas = document.getElementById("canvas");
                photo = document.getElementById("photo");
                refPhoto = document.getElementById("refPhoto");
                startbutton = document.getElementById("startbutton");

                navigator.mediaDevices
                    .getUserMedia({ video: true, audio: false })
                    .then((stream) => {
                        video.srcObject = stream;
                        video.play();
                    })
                    .catch((err) => {
                        console.error(`An error occurred: ${err}`);
                    });

                video.addEventListener(
                    "canplay",
                    (ev) => {
                        if (!streaming) {
                            height = video.videoHeight / (video.videoWidth / width);

                            // Firefox currently has a bug where the height can't be read from
                            // the video, so we will make assumptions if this happens.

                            if (isNaN(height)) {
                                height = width / (4 / 3);
                            }

                            video.setAttribute("width", width);
                            video.setAttribute("height", height);
                            canvas.setAttribute("width", width);
                            canvas.setAttribute("height", height);
                            streaming = true;
                        }
                    },
                    false
                );

                startbutton.addEventListener(
                    "click",
                    (ev) => {
                        takepicture();
                        ev.preventDefault();
                    },
                    false
                );

                clearphoto();
            }

            // Fill the photo with an indication that none has been
            // captured.

            function clearphoto() {
                const context = canvas.getContext("2d");
                context.fillStyle = "#AAA";
                context.fillRect(0, 0, canvas.width, canvas.height);

                const data = canvas.toDataURL("image/png");
                photo.setAttribute("src", data);
            }

            // Capture a photo by fetching the current contents of the video
            // and drawing it into a canvas, then converting that to a PNG
            // format data URL. By drawing it on an offscreen canvas and then
            // drawing that to the screen, we can change its size and/or apply
            // other changes before drawing it.

            async function takepicture() {
                const context = canvas.getContext("2d");
                if (width && height) {
                    canvas.width = width;
                    canvas.height = height;
                    context.drawImage(video, 0, 0, width, height);

                    const data = canvas.toDataURL("image/png");
                    photo.setAttribute("src", data);
                    if (!refPhoto.getAttribute("src")) refPhoto.setAttribute("src", data);
                    else {
                        const MODEL_URL = '/models'

                        await faceapi.loadSsdMobilenetv1Model(MODEL_URL)
                        await faceapi.loadFaceLandmarkModel(MODEL_URL)
                        await faceapi.loadFaceRecognitionModel(MODEL_URL)
                        const results = await faceapi
                            .detectAllFaces(refPhoto)
                            .withFaceLandmarks()
                            .withFaceDescriptors()

                        if (!results.length) {
                            return
                        }

                        // create FaceMatcher with automatically assigned labels
                        // from the detection results for the reference image
                        const maxDescriptorDistance = 0.5
                        const faceMatcher = new faceapi.FaceMatcher(results, maxDescriptorDistance)

                        const singleResult = await faceapi
                            .detectSingleFace(photo)
                            .withFaceLandmarks()
                            .withFaceDescriptor()

                        if (singleResult) {
                            const bestMatch = faceMatcher.findBestMatch(singleResult.descriptor)
                            console.log(bestMatch.toString())
                        }
                    }
                } else {
                    clearphoto();
                }
            }

            // Set up our event listener to run the startup process
            // once loading is complete.
            window.addEventListener("load", startup, false);
        })();

    </script>
</body>

</html>